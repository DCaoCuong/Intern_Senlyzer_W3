import { NextRequest, NextResponse } from 'next/server';
import Groq from "groq-sdk";

const groq = new Groq({ apiKey: process.env.GROQ_API_KEY });

interface TranscriptSegment {
    start: number;
    end: number;
    text: string;
}

interface ProcessedSegment {
    start: number;
    end: number;
    role: string;
    raw_text: string;
    clean_text: string;
}

/**
 * G·ªçi Groq Whisper API ƒë·ªÉ chuy·ªÉn audio th√†nh text
 */
async function transcribeWithGroq(audioBlob: Blob): Promise<{ text: string; segments: TranscriptSegment[] }> {
    const groqFormData = new FormData();
    groqFormData.append('file', audioBlob, 'recording.wav');
    groqFormData.append('model', 'whisper-large-v3');
    groqFormData.append('language', 'vi');
    groqFormData.append('response_format', 'verbose_json');

    const response = await fetch('https://api.groq.com/openai/v1/audio/transcriptions', {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${process.env.GROQ_API_KEY}` },
        body: groqFormData,
    });

    if (!response.ok) {
        throw new Error(`Groq API error: ${response.statusText}`);
    }

    const data = await response.json();

    return {
        text: data.text || '',
        segments: data.segments || []
    };
}

/**
 * Chuy·ªÉn transcription segments th√†nh format chu·∫©n cho LLM role detection
 */
function prepareSegmentsForRoleDetection(
    transcription: { text: string; segments: TranscriptSegment[] }
): { role: string; raw_text: string; start: number; end: number }[] {

    if (transcription.segments.length > 0) {
        return transcription.segments.map(seg => ({
            role: 'Ng∆∞·ªùi n√≥i', // Placeholder - LLM s·∫Ω x√°c ƒë·ªãnh role th·ª±c t·∫ø
            raw_text: seg.text,
            start: seg.start,
            end: seg.end
        }));
    }

    // Fallback n·∫øu kh√¥ng c√≥ segments
    if (transcription.text) {
        return [{
            role: 'Ng∆∞·ªùi n√≥i',
            raw_text: transcription.text,
            start: 0,
            end: 0
        }];
    }

    return [];
}

/**
 * S·ª≠ d·ª•ng LLM ƒë·ªÉ ph√¢n t√≠ch n·ªôi dung v√† x√°c ƒë·ªãnh vai tr√≤ ng∆∞·ªùi n√≥i
 * D·ª±a v√†o ng·ªØ c·∫£nh c·ªßa c√¢u n√≥i ƒë·ªÉ ƒëo√°n ai l√† B√°c sƒ©, ai l√† B·ªánh nh√¢n
 */
async function detectSpeakerRoleByContent(
    segments: { role: string; raw_text: string; start: number; end: number }[]
): Promise<{ role: string; raw_text: string; start: number; end: number }[]> {

    if (segments.length === 0) return segments;

    // T·∫°o prompt v·ªõi t·∫•t c·∫£ segments
    const conversationText = segments
        .map((seg, i) => `[${i}] "${seg.raw_text.trim()}"`)
        .join('\n');

    const prompt = `B·∫°n l√† chuy√™n gia ph√¢n t√≠ch h·ªôi tho·∫°i y khoa ti·∫øng Vi·ªát.
D∆∞·ªõi ƒë√¢y l√† transcript cu·ªôc kh√°m b·ªánh. H√£y x√°c ƒë·ªãnh vai tr√≤ ng∆∞·ªùi n√≥i cho t·ª´ng ƒëo·∫°n.

QUY T·∫ÆC X√ÅC ƒê·ªäNH VAI TR√í:
- B√ÅC Sƒ®: H·ªèi tri·ªáu ch·ª©ng, h·ªèi b·ªánh s·ª≠, ƒë∆∞a ra ch·∫©n ƒëo√°n, k√™ ƒë∆°n thu·ªëc, h∆∞·ªõng d·∫´n ƒëi·ªÅu tr·ªã
- B·ªÜNH NH√ÇN: M√¥ t·∫£ tri·ªáu ch·ª©ng ("t√¥i b·ªã...", "t√¥i th·∫•y..."), x∆∞ng "ch√†o b√°c sƒ©", tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ b·∫£n th√¢n

MANH M·ªêI QUAN TR·ªåNG:
- Ai n√≥i "Ch√†o b√°c sƒ©" ‚Üí B·ªÜNH NH√ÇN
- Ai h·ªèi "b·∫°n/anh/ch·ªã c√≥ tri·ªáu ch·ª©ng g√¨?" ‚Üí B√ÅC Sƒ®  
- Ai m√¥ t·∫£ "t√¥i ƒëau...", "t√¥i b·ªã..." ‚Üí B·ªÜNH NH√ÇN
- Ai h·ªèi "c√≥ s·ªët kh√¥ng?", "u·ªëng thu·ªëc g√¨ ch∆∞a?" ‚Üí B√ÅC Sƒ®

H·ªòI THO·∫†I:
${conversationText}

Tr·∫£ v·ªÅ CH√çNH X√ÅC ƒë·ªãnh d·∫°ng JSON array sau, KH√îNG c√≥ text kh√°c:
[{"index": 0, "role": "B√°c sƒ©"}, {"index": 1, "role": "B·ªánh nh√¢n"}, ...]`;

    try {
        console.log('üß† Analyzing speaker roles with LLM...');

        const chatCompletion = await groq.chat.completions.create({
            messages: [
                { role: "user", content: prompt }
            ],
            model: "llama-3.3-70b-versatile",
            temperature: 0.1,
            max_tokens: 500
        });

        const responseText = chatCompletion.choices[0]?.message?.content || '';
        console.log('üß† LLM response:', responseText.substring(0, 200));

        // Parse JSON response
        const jsonMatch = responseText.match(/\[[\s\S]*\]/);
        if (!jsonMatch) {
            console.warn('LLM did not return valid JSON, keeping original roles');
            return segments;
        }

        const roleAssignments: { index: number; role: string }[] = JSON.parse(jsonMatch[0]);

        // Update segments v·ªõi role m·ªõi t·ª´ LLM
        const updatedSegments = segments.map((seg, i) => {
            const assignment = roleAssignments.find(r => r.index === i);
            if (assignment) {
                console.log(`   [${i}] ${seg.role} ‚Üí ${assignment.role}`);
                return { ...seg, role: assignment.role };
            }
            return seg;
        });

        console.log('‚úÖ LLM role detection completed');
        return updatedSegments;

    } catch (error) {
        console.error('LLM role detection error:', error);
        // Fallback: keep original roles
        return segments;
    }
}

/**
 * S·ª≠ d·ª•ng Llama 3 ƒë·ªÉ s·ª≠a l·ªói thu·∫≠t ng·ªØ y khoa
 * CH·ªà s·ª≠a l·ªói ch√≠nh t·∫£, KH√îNG th√™m n·ªôi dung m·ªõi
 */
async function fixMedicalText(text: string): Promise<string> {
    if (!text || text.trim().length === 0) return text;

    try {
        const chatCompletion = await groq.chat.completions.create({
            messages: [
                {
                    role: "system",
                    content: `B·∫°n l√† chuy√™n gia hi·ªáu ch·ªânh vƒÉn b·∫£n y khoa ti·∫øng Vi·ªát.

NHI·ªÜM V·ª§: Ch·ªâ s·ª≠a l·ªói ch√≠nh t·∫£ v√† ph√°t √¢m sai trong ƒëo·∫°n vƒÉn ƒë∆∞·ª£c chuy·ªÉn t·ª´ gi·ªçng n√≥i.

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. TUY·ªÜT ƒê·ªêI KH√îNG th√™m n·ªôi dung m·ªõi
2. TUY·ªÜT ƒê·ªêI KH√îNG x√≥a b·ªõt n·ªôi dung
3. TUY·ªÜT ƒê·ªêI KH√îNG vi·∫øt l·∫°i c√¢u
4. Ch·ªâ s·ª≠a l·ªói ph√°t √¢m th∆∞·ªùng g·∫∑p:
   - "ƒëau th∆∞·ª£ng v·ªãt" ‚Üí "ƒëau th∆∞·ª£ng v·ªã"
   - "b·ªã s·ª•p" ‚Üí "b·ªã s·ªët"  
   - "ƒÉn ch√≠ch" ‚Üí "ƒÉn ki√™ng"
   - "ti√™u chu·∫©n" ‚Üí "tri·ªáu ch·ª©ng" (trong ng·ªØ c·∫£nh y khoa)
5. Gi·ªØ nguy√™n s·ªë t·ª´ v√† √Ω nghƒ©a g·ªëc
6. Tr·∫£ v·ªÅ CH√çNH X√ÅC ƒëo·∫°n vƒÉn g·ªëc v·ªõi l·ªói ƒë√£ s·ª≠a

V√ç D·ª§:
Input: "T√¥i b·ªã ƒëau th∆∞·ª£ng v·ªãt v√† s·ª•p t·ª´ h√¥m qua"
Output: "T√¥i b·ªã ƒëau th∆∞·ª£ng v·ªã v√† s·ªët t·ª´ h√¥m qua"

Input: "Xin ch√†o b·∫°n c√≥ nh·ªØng ti√™u chu·∫©n g√¨"
Output: "Xin ch√†o, b·∫°n c√≥ nh·ªØng tri·ªáu ch·ª©ng g√¨?"

KH√îNG BAO GI·ªú tr·∫£ v·ªÅ ƒëo·∫°n vƒÉn d√†i h∆°n ƒë√°ng k·ªÉ so v·ªõi input.`
                },
                { role: "user", content: text }
            ],
            model: "llama-3.3-70b-versatile",
            temperature: 0.05,
            max_tokens: Math.ceil(text.length * 1.5)
        });

        return chatCompletion.choices[0]?.message?.content || text;
    } catch (error) {
        console.error('Medical fixer error:', error);
        return text;
    }
}

/**
 * Main API Handler - X·ª≠ l√Ω audio v√† tr·∫£ v·ªÅ transcript v·ªõi speaker labels
 * Flow: Whisper STT ‚Üí LLM Role Detection ‚Üí Medical Text Fixer
 */
export async function POST(req: NextRequest) {
    const formData = await req.formData();
    const file = formData.get('file') as Blob;

    if (!file) {
        return NextResponse.json({ error: "No audio file provided" }, { status: 400 });
    }

    try {
        console.log(`üìÅ Received audio: ${file.size} bytes`);

        // Step 1: Whisper STT - Chuy·ªÉn audio th√†nh text
        console.log('üé§ Running Whisper STT...');
        const transcription = await transcribeWithGroq(file);
        console.log(`üìù Transcription: ${transcription.text.substring(0, 100)}...`);
        console.log(`üìä Segments count: ${transcription.segments.length}`);

        // N·∫øu kh√¥ng c√≥ text, tr·∫£ v·ªÅ empty
        if (!transcription.text || transcription.text.trim().length === 0) {
            return NextResponse.json({
                success: true,
                segments: [],
                raw_text: "",
                num_speakers: 0
            });
        }

        // Step 2: Prepare segments for role detection
        const preparedSegments = prepareSegmentsForRoleDetection(transcription);
        console.log(`üîó Prepared segments: ${preparedSegments.length}`);

        // Step 3: LLM Role Detection - Ph√¢n t√≠ch n·ªôi dung ƒë·ªÉ x√°c ƒë·ªãnh B√°c sƒ©/B·ªánh nh√¢n
        const segmentsWithRoles = await detectSpeakerRoleByContent(preparedSegments);

        // Step 4: Medical Text Fixer - S·ª≠a l·ªói thu·∫≠t ng·ªØ y khoa
        console.log('üíä Running Medical Text Fixer...');
        const processedSegments: ProcessedSegment[] = await Promise.all(
            segmentsWithRoles.map(async (seg) => ({
                ...seg,
                clean_text: await fixMedicalText(seg.raw_text)
            }))
        );

        console.log('‚úÖ Processing complete!');

        return NextResponse.json({
            success: true,
            segments: processedSegments,
            raw_text: transcription.text,
            num_speakers: 2 // Assumed 2 speakers (Doctor + Patient)
        });

    } catch (error) {
        console.error('‚ùå Processing error:', error);
        return NextResponse.json(
            { error: "L·ªói x·ª≠ l√Ω h·ªá th·ªëng", details: String(error) },
            { status: 500 }
        );
    }
}

/**
 * Health check endpoint
 */
export async function GET() {
    return NextResponse.json({
        status: 'ok',
        services: {
            groq_stt: process.env.GROQ_API_KEY ? 'configured' : 'missing_key',
            llm_role_detection: 'ready',
            medical_fixer: 'ready'
        },
        note: 'Diarization removed - using LLM Context Analysis for speaker role detection'
    });
}